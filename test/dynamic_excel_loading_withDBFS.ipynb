{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "750327e8-93a7-460b-afa7-fcd20545a6a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "dbutils.widgets.text(label=\"Source Directory\", name=\"source_path\", defaultValue='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab8f59c3-f5c0-4889-a3be-13f7fb00e03a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema_name = spark.catalog.currentDatabase()\n",
    "catalog_name = spark.conf.get(\"spark.sql.catalogImplementation\")\n",
    "\n",
    "# print(f\"Schema Name: {schema_name}\")\n",
    "# print(f\"Catalog Name: {catalog_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac0d3d5b-d38c-4ae4-91fd-102486e45007",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "use catalog dev_edh;\n",
    "use schema default;\n",
    "--select count(*) from dev_edh.default.delta_source;\n",
    "--truncate TABLE dev_poc.default.delta_source;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29965bdb-1fbd-4358-bfc7-135c816df47f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = []  # Initialize an empty list to store data\n",
    "cols = ['FileName', 'SheetName', 'ModificationTime', 'LoadTime', 'Data']  # Define column names for the data\n",
    "directory = 'dbfs:/user/arundhuti/delta/'  # Define the directory path in DBFS\n",
    "\n",
    "# Read the existing data to get the list of already processed files\n",
    "existing_df = spark.read.format(\"parquet\").load(\"dbfs:/user/arundhuti/delta/aru_delta_source\")\n",
    "existing_files = existing_df.select(\"FileName\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# Iterate over each item in the specified directory\n",
    "for item in dbutils.fs.ls(directory):\n",
    "    # Check if the item is an Excel file with .xlsx extension and not already processed\n",
    "    if item.path[-5:] == '.xlsx' and item.path[5:] not in existing_files:\n",
    "        # Copy the file from DBFS to the local file system\n",
    "        local_path = f\"/tmp/{item.name}\"\n",
    "        dbutils.fs.cp(item.path, f\"file:{local_path}\")\n",
    "        \n",
    "        # Read the Excel file to get sheet names\n",
    "        sheets = pd.ExcelFile(local_path)\n",
    "        # Print the sheet names in the Excel file\n",
    "        if len(sheets.sheet_names) >= 1:\n",
    "            for sheet in sheets.sheet_names:\n",
    "                pdf = pd.read_excel(local_path, sheet_name=sheet)\n",
    "                modfied_time = int(item.modificationTime/1000)\n",
    "                value = pdf.to_json(orient='split')\n",
    "                load_time = time.strftime(\"%Y%m%d:%H:%M:%S\", time.localtime())      \n",
    "                data.append([item.path[5:], sheet, time.strftime('%Y%m%d:%H:%M:%S', time.localtime(modfied_time)), load_time, value])\n",
    "                df = spark.createDataFrame(data, cols)      \n",
    "                df.write.format(\"parquet\").mode(\"append\").save(\"dbfs:/user/arundhuti/delta/aru_delta_source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8df5c6b7-7a6a-495b-b33c-a2a73f3d264d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM PARQUET.`dbfs:/user/arundhuti/delta/aru_delta_source`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e723ad1-9244-4ae4-9e0c-58ce84b76f29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM PARQUET.`dbfs:/user/arundhuti/delta/aru_delta_source` \n",
    "WHERE loadtime = (SELECT MAX(loadtime) FROM PARQUET.`dbfs:/user/arundhuti/delta/aru_delta_source`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2691e0b1-42ba-4e5a-b1e3-f545b1d51d15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.mv('dbfs:/FileStore/read_Jan.xlsx','dbfs:/user/arundhuti/delta/')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6631007572061070,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "dynamic_excel_loading_withDBFS",
   "widgets": {
    "source_path": {
     "currentValue": "dbfs:/user/arundhuti/delta/",
     "nuid": "cc3220a4-644e-4e1e-8ea2-88ef91b13292",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Source Directory",
      "name": "source_path",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Source Directory",
      "name": "source_path",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
