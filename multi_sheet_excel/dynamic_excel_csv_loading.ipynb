{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa592b64-036e-463a-8ad1-16d7c4707c02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create a dropdown widget from where I will chose excel or csv\n",
    "dbutils.widgets.dropdown(\"source_extention\", \"excel\", [\"excel\", \"csv\"]) \n",
    "#get that widget value and save in a variable name\n",
    "source_extention = dbutils.widgets.get(\"source_extention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46bf9cb3-9855-4ffd-b57d-22de90c1fa8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--drop table dev_edh.dummy.delta_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac0d3d5b-d38c-4ae4-91fd-102486e45007",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "use catalog dev_edh;\n",
    "use schema dummy;\n",
    "--select count(*) from dev_edh.dummy.delta_source;\n",
    "--truncate TABLE dev_poc.default.delta_source;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "750327e8-93a7-460b-afa7-fcd20545a6a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "dbutils.widgets.text(label=\"Source Directory\", name=\"source_path\", defaultValue='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b5daea5-4edd-4166-8e97-ab72fb81774f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The code iterates through files in a specified directory, filtering files based on the extension stored in the variable 'source_extention'.\n",
    "For each matching file, it reads all sheets in the Excel file.\n",
    "For each sheet, it reads the data into a DataFrame, retrieves the file's modification time, and records the current load time.\n",
    "It converts the sheet data to JSON format and appends a list containing the file path, sheet name, modification time, load time, and data to a list.\n",
    "Then, it creates a Spark DataFrame from this list with specified columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29965bdb-1fbd-4358-bfc7-135c816df47f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "data = []  # Initialize an empty list to store data\n",
    "cols = ['FileName', 'SheetName', 'ModificationTime', 'LoadTime', 'Data']  # Define column names for the DataFrame\n",
    "directory = dbutils.widgets.get(\"source_path\")  # Get the directory path from the widget\n",
    "list_files = os.listdir(directory)  # List all files in the directory\n",
    "\n",
    "for item in list_files:\n",
    "    file_path = os.path.join(directory, item)  # Get the full file path\n",
    "    # Check if the file extension matches the selected source extension\n",
    "    if source_extention == \"excel\" and item.endswith('.xlsx'):\n",
    "        sheets = pd.ExcelFile(file_path)  # Read the Excel file\n",
    "        if len(sheets.sheet_names) >= 1:  # Check if there is at least one sheet\n",
    "            for sheet in sheets.sheet_names:  # Iterate through each sheet\n",
    "                pdf = pd.read_excel(file_path, sheet_name=sheet)  # Read the sheet into a DataFrame\n",
    "                modfied_time = int(os.path.getmtime(file_path) / 1000)  # Get the file modification time\n",
    "                value = pdf.to_json(orient='split')  # Convert the DataFrame to JSON\n",
    "                load_time = time.strftime(\"%Y%m%d:%H:%M:%S\", time.localtime())  # Get the current load time\n",
    "\n",
    "                # Append the data to the list\n",
    "                data.append([file_path, sheet, time.strftime('%Y%m%d:%H:%M:%S', time.localtime(modfied_time)), load_time, value])\n",
    "            df = spark.createDataFrame(data, cols)  # Create a Spark DataFrame from the data list    \n",
    "    elif source_extention == \"csv\" and item.endswith('.csv'):\n",
    "        pdf = pd.read_csv(file_path, encoding='ISO-8859-1')  # Read the CSV file into a DataFrame\n",
    "        modfied_time = int(os.path.getmtime(file_path) / 1000)  # Get the file modification time\n",
    "        value = pdf.to_json(orient='split')  # Convert the DataFrame to JSON\n",
    "        load_time = time.strftime(\"%Y%m%d:%H:%M:%S\", time.localtime())  # Get the current load time\n",
    "\n",
    "        # Append the data to the list\n",
    "        data.append([file_path, None, time.strftime('%Y%m%d:%H:%M:%S', time.localtime(modfied_time)), load_time, value])\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('FileName', StringType(), True),\n",
    "    StructField('SheetName', StringType(), True),\n",
    "    StructField('ModificationTime', StringType(), True),\n",
    "    StructField('LoadTime', StringType(), True),\n",
    "    StructField('Data', StringType(), True)\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data, schema)  # Create a Spark DataFrame with explicit schema\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8608737-8187-414f-9ba4-ab91ab625aaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#create a table called delta_source\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"delta_source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27d52407-4013-4bc7-b855-c2f62fc2b38f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7107324-5941-4482-9dc6-7d1a7190f0d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df2 = df.filter((df['FileName'] == '/dbfs/user/arundhuti/delta/Dynamic_Excel_Source_Data/data_detail.xlsx') & (df['SheetName'] == 'Member')).select('Data')\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c77cef1-02f7-4e11-9358-9def85b78768",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "df3 = json.loads(df2.collect()[0]['Data'])\n",
    "cols = df3['columns']\n",
    "data = df3['data']\n",
    "sdf = spark.createDataFrame(data, cols)\n",
    "display(sdf)\n",
    "#df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "768fab18-ab1a-4dce-ba7b-e0ab3db0fcbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "current_time = time.strftime(\"%Y%m%d:%H:%M:%S\",time.localtime())\n",
    "current_time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8df5c6b7-7a6a-495b-b33c-a2a73f3d264d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--select * from dev_edh.dummy.delta_source"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7533939325247939,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "dynamic_excel_csv_loading",
   "widgets": {
    "source_extention": {
     "currentValue": "excel",
     "nuid": "9f2e9dce-e7c4-4925-82b9-de8d1048342f",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "excel",
      "label": null,
      "name": "source_extention",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "excel",
        "csv"
       ],
       "fixedDomain": true,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "excel",
      "label": null,
      "name": "source_extention",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "excel",
        "csv"
       ]
      }
     }
    },
    "source_path": {
     "currentValue": "/dbfs/user/arundhuti/delta/Dynamic_Excel_Source_Data/",
     "nuid": "cc3220a4-644e-4e1e-8ea2-88ef91b13292",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Source Directory",
      "name": "source_path",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Source Directory",
      "name": "source_path",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
